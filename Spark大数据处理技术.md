# Spark大数据处理技术读书笔记

MapReduce缺乏一种特性，即在并行计算的各个阶段进行有效的数据共享，这种共享就是RDD的本质。

RDD依赖关系

窄依赖和宽依赖的区别

窄依赖可以在集群的一个节点上如流水线一般地执行，可以计算所有父RDD的分区

宽依赖需要取得父RDD的所有分区进行计算，将会执行类似于MR一样的Shuffle操作。

窄依赖，节点计算失败后的恢复会更加有效，只需要重新计算对应的父RDD的分区，而且可以在其他的节点上并行的计算。

宽依赖中，一个节点的失败将会导致其父RDD的多个分区重新计算，代价非常高。

- 窄依赖
- 宽依赖

groupByKey与reduceByKey的主要区别： 
1、groupByKey算子的功能固定，只能输出相同key值的序列，reduceByKey适用于分组排序过程中有数据聚合操作（sum）的情形，在其他场景下可能不适用。 
2、reduceByKey算子在分区内会进行数据聚合操作，因此针对有sum的数据聚合操作,效率会更高一些。（groupByKey算子也能实现类似sum的数据聚合操作，相当于进行groupByKey操作后还需进行map类算子的sum操作）

> [参考](http://www.cnblogs.com/bonelee/p/7111395.html)

# SPARK里的shuffle

- shuffle中文一般称为 **数据混洗**。
- shuffle的官方定义是，它是spark的一种让数据重新分布以使得某些数据被放在同一分区里的一种机制。

域维表又分解为国家，省份，城市等维表。