# 大数据技术比较

Blink vs Flink vs Strom vs Spark vs Hadoop



Flink

1. Flink 几个最基础的概念，***Client、JobManager 和 TaskManager***。Client 用来提交任务给JobManager，JobManager 分发任务给 TaskManager 去执行，然后 TaskManager 会心跳的汇报任务状态。看到这里，有的人应该已经有种回到 Hadoop 一代的错觉。确实，从架构图去看，JobManager 很像当年的 JobTracker，TaskManager 也很像当年的 TaskTracker。然而有一个最重要的区别就是 TaskManager 之间是是流（Stream）。其次，Hadoop 一代中，只有 Map 和 Reduce 之间的 Shuffle，而对 Flink 而言，可能是很多级，并且在 TaskManager内部和 TaskManager 之间都会有数据传递，而不像 Hadoop，是固定的 Map 到 Reduce。

2. Flink在JVM内部实现了自己的内存管理

3. **整合支持**

   支持Flink on YARN

   支持HDFS

   支持来自Kafka的输入数据

   支持Apache HBase

   支持Hadoop程序

   支持Tachyon

   支持ElasticSearch

   支持RabbitMQ

   支持Apache Storm

   支持S3

   支持XtreemFS

4. **Flink 的 HA**
	我们需要知道 Flink 有两种部署的模式，分别是*** Standalone 以及 Yarn Cluster 模式***。对于 Standalone 来说，Flink 必须依赖于 Zookeeper 来实现 JobManager 的 HA（Zookeeper 已经成为了大部分开源框架 HA 必不可少的模块）。在 Zookeeper 的帮助下，一个 Standalone 的 Flink 集群会同时有多个活着的 JobManager，其中只有一个处于工作状态，其他处于 Standby 状态。当工作中的 JobManager 失去连接后（如宕机或 Crash），Zookeeper 会从Standby 中选举新的 JobManager 来接管 Flink 集群。

	对于 Yarn Cluaster 模式来说，Flink 就要依靠 Yarn 本身来对 JobManager 做 HA 了。其实这里完全是 Yarn 的机制。对于 Yarn Cluster 模式来说，JobManager 和 TaskManager 都是被 Yarn 启动在 Yarn 的 Container 中。此时的JobManager，其实应该称之为 Flink Application Master。也就说它的故障恢复，就完全依靠着 Yarn 中的ResourceManager（和 MapReduce 的 AppMaster 一样）。由于完全依赖了 Yarn，因此不同版本的 Yarn 可能会有细微的差异。这里不再做深究。
	

Strom





Spark Streaming



Hadoop





